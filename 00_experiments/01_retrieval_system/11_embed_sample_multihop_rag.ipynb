{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "import uuid\n",
    "import json\n",
    "import tiktoken\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# === Configuration ===\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "EMBEDDING_SVC_URL = \"http://127.0.0.1:8000/embed\"\n",
    "COLLECTION_NAME = \"multihop_rag_sample\"\n",
    "VECTOR_SIZE = 384\n",
    "MAX_TOKENS = 256\n",
    "CHUNK_OVERLAP = 32\n",
    "LLM = \"gpt-4o\"\n",
    "\n",
    "\n",
    "# === UTILS ===\n",
    "def chunk_text_by_tokens(\n",
    "    tokenizer: tiktoken.core.Encoding, text: str, max_tokens: int = 256\n",
    "):\n",
    "\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk_tokens = tokens[i : i + max_tokens]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def chunk_text_with_overlap(\n",
    "    tokenizer: tiktoken.core.Encoding, \n",
    "    text: str, \n",
    "    max_tokens=256, \n",
    "    overlap=32\n",
    "):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = tokens[start:end]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def generate_chunk_id(url: str, chunk_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a deterministic UUID based on URL + chunk text.\n",
    "    Ensures same content always yields same ID.\n",
    "    \"\"\"\n",
    "    hash_input = (url + chunk_text).encode(\"utf-8\")\n",
    "    hash_bytes = hashlib.sha1(hash_input).digest()  # or sha256 for stronger hashing\n",
    "    return str(uuid.UUID(bytes=hash_bytes[:16]))\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(LLM)\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(url=QDRANT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f11c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get Corpus Data\n",
    "with open(\"./multihop_rag/corpus_sample.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb5404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_insert = []\n",
    "\n",
    "for article_idx, article in enumerate(articles):\n",
    "    body = article.get(\"body\", \"\")\n",
    "    if not body:\n",
    "        continue\n",
    "\n",
    "    chunks = chunk_text_with_overlap(\n",
    "        tokenizer=tokenizer, text=body, max_tokens=MAX_TOKENS, overlap=CHUNK_OVERLAP\n",
    "    )\n",
    "\n",
    "    payload = {\"texts\": chunks}\n",
    "    resp = requests.post(EMBEDDING_SVC_URL, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    embeddings = resp.json()[\"embeddings\"]  # list of vectors\n",
    "\n",
    "    for chunk_id, (chunk_text, emb) in enumerate(zip(chunks, embeddings)):\n",
    "        # copy the metadata of the article to the chunk\n",
    "        payload_doc = {k: v for k, v in article.items() if k != \"body\"}\n",
    "        payload_doc[\"chunk_id\"] = chunk_id\n",
    "        payload_doc[\"num_tokens\"] = len(tokenizer.encode(chunk_text))\n",
    "        payload_doc[\"body_chunk\"] = chunk_text\n",
    "\n",
    "        # insert chunks\n",
    "        points_to_insert.append(\n",
    "            models.PointStruct(id=generate_chunk_id(article[\"url\"], chunk_text), vector=emb, payload=payload_doc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a928db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=6, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bulk upsert for efficiency\n",
    "qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points_to_insert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
